name: Crawl and Post (All-in-One)

on:
  schedule:
    # 매일 오전 10시, 오후 3시, 오후 8시 실행 (KST)
    - cron: '0 1,6,11 * * *'  # UTC 기준
  workflow_dispatch:  # 수동 실행 가능
    inputs:
      skip_crawl:
        description: 'Skip crawling (only post existing)'
        required: false
        type: boolean
        default: false

jobs:
  crawl-and-post:
    runs-on: ubuntu-latest
    timeout-minutes: 45
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '20'
        cache: 'npm'
    
    - name: Install dependencies
      run: |
        npm config set loglevel warn
        npm config set progress false
        npm ci --prefer-offline --no-optional || npm install --legacy-peer-deps --no-audit --no-fund
      timeout-minutes: 8
    
    - name: Install Playwright browsers
      run: npx playwright install chromium
      timeout-minutes: 5
    
    # 크롤링 단계
    - name: Run crawler
      if: github.event.inputs.skip_crawl != 'true'
      env:
        SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
        SUPABASE_ANON_KEY: ${{ secrets.SUPABASE_ANON_KEY }}
        NAVER_ID: ${{ secrets.NAVER_ID }}
        NAVER_PASSWORD: ${{ secrets.NAVER_PASSWORD }}
        NAVER_COOKIES: ${{ secrets.NAVER_COOKIES }}
        HEADLESS: 'true'
        GITHUB_ACTIONS: 'true'
      timeout-minutes: 20
      run: |
        echo "🕷️ 네이버 카페 크롤링 시작"
        
        if [ -n "${{ secrets.NAVER_COOKIES }}" ]; then
          echo "🍪 저장된 쿠키로 로그인 시도"
        else
          echo "🔐 네이버 로그인 후 전체 게시글 수집"
        fi
        
        node crawler-stealth.js || {
          echo "⚠️ Stealth 크롤러 실패, 개선된 크롤러 시도"
          node crawler-improved.js || {
            echo "⚠️ 개선된 크롤러 실패, 로그인 크롤러 시도"
            node crawler-advanced.js || {
              echo "⚠️ 로그인 크롤러 실패, 직접 URL 크롤러 시도"
              node crawler-direct.js || {
                echo "⚠️ 직접 크롤러 실패, 공개 게시글 크롤러 시도"
                node crawler-public.js || echo "⚠️ 크롤링 중 일부 오류 발생 (계속 진행)"
              }
            }
          }
        }
        echo "✅ 크롤링 단계 완료"
    
    # 30분 대기 (크롤링 데이터 안정화)
    - name: Wait 30 minutes after crawling
      if: github.event.inputs.skip_crawl != 'true'
      run: |
        echo "⏰ 크롤링 데이터 안정화를 위해 30분 대기 중..."
        echo "🕐 대기 시작: $(date '+%Y-%m-%d %H:%M:%S')"
        sleep 1800  # 30분 = 1800초
        echo "✅ 대기 완료: $(date '+%Y-%m-%d %H:%M:%S')"
    
    # 크롤링 건너뛴 경우 짧은 대기
    - name: Short wait for DB sync
      if: github.event.inputs.skip_crawl == 'true'
      run: sleep 5
    
    # 포스팅 단계
    - name: Run auto poster (all today's posts)
      env:
        SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
        SUPABASE_ANON_KEY: ${{ secrets.SUPABASE_ANON_KEY }}
        NAVER_ID: ${{ secrets.NAVER_ID }}
        NAVER_PASSWORD: ${{ secrets.NAVER_PASSWORD }}
        HEADLESS: 'true'
      timeout-minutes: 30  # 10개 게시글 업로드 시간 고려
      run: |
        echo "🚀 오늘 크롤링한 모든 게시글 포스팅 시작"
        echo "📅 날짜: $(date '+%Y-%m-%d')"
        
        # 오늘자 모든 게시글 업로드
        node auto-post-all-today.js
        
        echo "✅ 포스팅 단계 완료"
    
    - name: Summary
      if: always()
      run: |
        echo "## 📊 작업 요약" >> $GITHUB_STEP_SUMMARY
        echo "- 크롤링: ${{ github.event.inputs.skip_crawl != 'true' && '실행됨' || '건너뜀' }}" >> $GITHUB_STEP_SUMMARY
        echo "- 포스팅: 실행됨" >> $GITHUB_STEP_SUMMARY
        echo "- 전체 상태: ${{ job.status }}" >> $GITHUB_STEP_SUMMARY