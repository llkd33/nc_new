name: Crawl and Post (All-in-One)

on:
  schedule:
    # ë§¤ì¼ ì˜¤ì „ 10ì‹œ, ì˜¤í›„ 3ì‹œ, ì˜¤í›„ 8ì‹œ ì‹¤í–‰ (KST)
    - cron: '0 1,6,11 * * *'  # UTC ê¸°ì¤€
  workflow_dispatch:  # ìˆ˜ë™ ì‹¤í–‰ ê°€ëŠ¥
    inputs:
      skip_crawl:
        description: 'Skip crawling (only post existing)'
        required: false
        type: boolean
        default: false

jobs:
  crawl-and-post:
    runs-on: ubuntu-latest
    timeout-minutes: 45
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '20'
        cache: 'npm'
    
    - name: Install dependencies
      run: |
        npm config set loglevel warn
        npm config set progress false
        npm ci --prefer-offline --no-optional || npm install --legacy-peer-deps --no-audit --no-fund
      timeout-minutes: 8
    
    - name: Install Playwright browsers
      run: npx playwright install chromium
      timeout-minutes: 5
    
    # í¬ë¡¤ë§ ë‹¨ê³„
    - name: Run crawler
      if: github.event.inputs.skip_crawl != 'true'
      env:
        SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
        SUPABASE_ANON_KEY: ${{ secrets.SUPABASE_ANON_KEY }}
        NAVER_ID: ${{ secrets.NAVER_ID }}
        NAVER_PASSWORD: ${{ secrets.NAVER_PASSWORD }}
        NAVER_COOKIES: ${{ secrets.NAVER_COOKIES }}
        HEADLESS: 'true'
        GITHUB_ACTIONS: 'true'
      timeout-minutes: 20
      run: |
        echo "ðŸ•·ï¸ ë„¤ì´ë²„ ì¹´íŽ˜ í¬ë¡¤ë§ ì‹œìž‘"
        
        if [ -n "${{ secrets.NAVER_COOKIES }}" ]; then
          echo "ðŸª ì €ìž¥ëœ ì¿ í‚¤ë¡œ ë¡œê·¸ì¸ ì‹œë„"
        else
          echo "ðŸ” ë„¤ì´ë²„ ë¡œê·¸ì¸ í›„ ì „ì²´ ê²Œì‹œê¸€ ìˆ˜ì§‘"
        fi
        
        node crawler-stealth.js || {
          echo "âš ï¸ Stealth í¬ë¡¤ëŸ¬ ì‹¤íŒ¨, ê°œì„ ëœ í¬ë¡¤ëŸ¬ ì‹œë„"
          node crawler-improved.js || {
            echo "âš ï¸ ê°œì„ ëœ í¬ë¡¤ëŸ¬ ì‹¤íŒ¨, ë¡œê·¸ì¸ í¬ë¡¤ëŸ¬ ì‹œë„"
            node crawler-advanced.js || {
              echo "âš ï¸ ë¡œê·¸ì¸ í¬ë¡¤ëŸ¬ ì‹¤íŒ¨, ì§ì ‘ URL í¬ë¡¤ëŸ¬ ì‹œë„"
              node crawler-direct.js || {
                echo "âš ï¸ ì§ì ‘ í¬ë¡¤ëŸ¬ ì‹¤íŒ¨, ê³µê°œ ê²Œì‹œê¸€ í¬ë¡¤ëŸ¬ ì‹œë„"
                node crawler-public.js || echo "âš ï¸ í¬ë¡¤ë§ ì¤‘ ì¼ë¶€ ì˜¤ë¥˜ ë°œìƒ (ê³„ì† ì§„í–‰)"
              }
            }
          }
        }
        echo "âœ… í¬ë¡¤ë§ ë‹¨ê³„ ì™„ë£Œ"
    
    # 30ë¶„ ëŒ€ê¸° (í¬ë¡¤ë§ ë°ì´í„° ì•ˆì •í™”)
    - name: Wait 30 minutes after crawling
      if: github.event.inputs.skip_crawl != 'true'
      run: |
        echo "â° í¬ë¡¤ë§ ë°ì´í„° ì•ˆì •í™”ë¥¼ ìœ„í•´ 30ë¶„ ëŒ€ê¸° ì¤‘..."
        echo "ðŸ• ëŒ€ê¸° ì‹œìž‘: $(date '+%Y-%m-%d %H:%M:%S')"
        sleep 1800  # 30ë¶„ = 1800ì´ˆ
        echo "âœ… ëŒ€ê¸° ì™„ë£Œ: $(date '+%Y-%m-%d %H:%M:%S')"
    
    # í¬ë¡¤ë§ ê±´ë„ˆë›´ ê²½ìš° ì§§ì€ ëŒ€ê¸°
    - name: Short wait for DB sync
      if: github.event.inputs.skip_crawl == 'true'
      run: sleep 5
    
    # í¬ìŠ¤íŒ… ë‹¨ê³„
    - name: Run auto poster (all today's posts)
      env:
        SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
        SUPABASE_ANON_KEY: ${{ secrets.SUPABASE_ANON_KEY }}
        NAVER_ID: ${{ secrets.NAVER_ID }}
        NAVER_PASSWORD: ${{ secrets.NAVER_PASSWORD }}
        HEADLESS: 'true'
      timeout-minutes: 30  # 10ê°œ ê²Œì‹œê¸€ ì—…ë¡œë“œ ì‹œê°„ ê³ ë ¤
      run: |
        echo "ðŸš€ ì˜¤ëŠ˜ í¬ë¡¤ë§í•œ ëª¨ë“  ê²Œì‹œê¸€ í¬ìŠ¤íŒ… ì‹œìž‘"
        echo "ðŸ“… ë‚ ì§œ: $(date '+%Y-%m-%d')"
        
        # ì˜¤ëŠ˜ìž ëª¨ë“  ê²Œì‹œê¸€ ì—…ë¡œë“œ
        node auto-post-all-today.js
        
        echo "âœ… í¬ìŠ¤íŒ… ë‹¨ê³„ ì™„ë£Œ"
    
    - name: Summary
      if: always()
      run: |
        echo "## ðŸ“Š ìž‘ì—… ìš”ì•½" >> $GITHUB_STEP_SUMMARY
        echo "- í¬ë¡¤ë§: ${{ github.event.inputs.skip_crawl != 'true' && 'ì‹¤í–‰ë¨' || 'ê±´ë„ˆëœ€' }}" >> $GITHUB_STEP_SUMMARY
        echo "- í¬ìŠ¤íŒ…: ì‹¤í–‰ë¨" >> $GITHUB_STEP_SUMMARY
        echo "- ì „ì²´ ìƒíƒœ: ${{ job.status }}" >> $GITHUB_STEP_SUMMARY